# âš™ï¸ Optimisation CPU/GPU â€” Calcul QuÃ©bec

## ðŸš€ PrÃ©sentation
- **PrÃ©sentation** : [PowerPoint](https://docs.google.com/presentation/d/1tS6q2KERVvBToZFm4_9leqUagaYb36qte5mPQLuXojc)

---

## ðŸŽ¯ Objectif

- **Optimiser lâ€™utilisation des ressources** CPU / GPU  
- **Ã‰viter le gaspillage** : des ressources demandÃ©es mais non utilisÃ©es sont **perdues**  
- **Surveiller lâ€™efficacitÃ© des tÃ¢ches** et leur adÃ©quation aux ressources demandÃ©es  

---

## ðŸ“Š SystÃ¨me de Priorisation

- **Ordonnancement via SLURM**  
- La **prioritÃ© est partagÃ©e** entre les membres dâ€™un mÃªme projet  
- **Bonnes pratiques influencent la prioritÃ©** :  
  - âœ… **Demander moins** que la cible â†’ **prioritÃ© augmente**  
  - âŒ **DÃ©passer** la cible â†’ **prioritÃ© diminue**  
- La **prioritÃ© se rÃ©gÃ©nÃ¨re automatiquement** avec une **demi-vie dâ€™une semaine**  

ðŸ“Œ **VÃ©rifier la prioritÃ© actuelle** :  
```bash
sshare -l -A def-prof -u prof1,grad2,postdoc3
```
- Valeur > 1 : prioritÃ© Ã©levÃ©e  
- Valeur < 1 : prioritÃ© faible  

---

## ðŸ§  StratÃ©gies de Soumission

- **Segmenter les calculs** sur diffÃ©rentes grappes (Narval, BÃ©lugaâ€¦)  
- **VÃ©rifier les portails** :  
  - [Narval](https://portail.narval.calculquebec.ca)  
  - [BÃ©luga](https://portail.beluga.calculquebec.ca)  
  - [Documentation des portails](https://docs.alliancecan.ca/wiki/Portail)  

ðŸ’¡ Une tÃ¢che finie **plus tÃ´t** ne coÃ»te que le temps utilisÃ©, mais **rÃ©duit la prioritÃ©**  

---

## ðŸ§µ Processus vs Fils dâ€™exÃ©cution

- **Processus** : Instance autonome dâ€™un programme  
- **Fils (threads)** : UnitÃ©s dâ€™exÃ©cution au sein dâ€™un processus (partagent code, mÃ©moire, variables) 

---

## ðŸ–¥ï¸ ParamÃ©trage des TÃ¢ches

- `--cpus-per-task=1` â†’ ExÃ©cution **sÃ©rielle**  
- TÃ¢ches **multithread** :  
  - Plusieurs **threads** dans un **mÃªme** processus  
  - **MÃ©moire partagÃ©e**  
  - **Tous les CPUs** doivent Ãªtre utilisÃ©s  
  - ðŸ§  **20 % de mÃ©moire en trop** : OK. Au-delÃ  â†’ Ã  ajuster  

- TÃ¢ches **multiprocesseur** :  
  - Plusieurs **processus** parallÃ¨les  
  - **MÃ©moire distribuÃ©e**, non partagÃ©e  
  - Utiliser `srun` pour lancer la tÃ¢che (ex : MPI)  
  - `--ntasks=3` â†’ 3 processus, possiblement rÃ©partis sur plusieurs nÅ“uds  

ðŸ’¡ Les **nÅ“uds Ã  grande mÃ©moire** sont rares â†’ temps dâ€™attente potentiellement long  

ðŸ”´ `--mem=0` â†’ Demande **toute la mÃ©moire du nÅ“ud**  

---

## ðŸ§  Adapter les Ressources

- **VÃ©rifier la doc des librairies utilisÃ©es** pour :  
  - Threading ?  
  - Besoins mÃ©moire ?  
  - Utilisation CPU/GPU ?  

---

## ðŸ§ª GPU â€” Bonnes Pratiques

- **Narval** : 4 GPU A100 par nÅ“ud (40 Go chacun)  
- **SM Active** : > 80 %  
- **SM Occupancy** : > 50 %  
- **Tensor Utilisation** : aussi haut que possible  

ðŸ“Š VÃ©rifier lâ€™utilisation sur le portail de la grappe  

---

## ðŸ§© GPU : Profils & MIG

- **MIG (Multi-Instance GPU)** :  
  - Fractionnement dâ€™un GPU en sous-unitÃ©s indÃ©pendantes  
  - âœ… Temps dâ€™attente rÃ©duit  
  - âž• IdÃ©al pour des tÃ¢ches GPU > 10 %  

ðŸ“Œ Exemple de profil MIG :  
```bash
--gres=gpu:a100_3g.20g:1
```
â†’ GPU A100, profil 3g.20g (20 Go)  

ðŸ”§ Profils disponibles :  
- `1g.5gb`, `2g.10gb`, `3g.20gb`, `4g.20gb`
